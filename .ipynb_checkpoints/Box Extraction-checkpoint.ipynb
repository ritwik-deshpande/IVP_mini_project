{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "import math\n",
    "import operator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = crop_and_warp(img,find_corners_of_largest_polygon(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyAdaptive(img):\n",
    "    img_bin = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    return img_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding the image\n",
    "\n",
    "def main_function(img_bin):\n",
    "   \n",
    "    # Invert the image\n",
    "    img_bin = 255-img_bin\n",
    "\n",
    "    # cv2.imshow('binary image',img_bin)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    return img_final_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "# initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 1\n",
    "\n",
    "#     # handle if we need to sort in reverse\n",
    "#     if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "#         reverse = True\n",
    "\n",
    "#     # handle if we are sorting against the y-coordinate rather than\n",
    "#     # the x-coordinate of the bounding box\n",
    "#     if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "#         i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    \n",
    "    print(boundingBoxes[0])\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),key=lambda b:b[i][1], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img_final_bin):\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort all the contours by top to bottom.\n",
    "    #(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "    contours.sort(key=lambda x:get_contour_precedence(x, img.shape[1]))\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewImages(contours):\n",
    "    row = 0\n",
    "    col = 6\n",
    "\n",
    "    retval = []\n",
    "    new_images = list()\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "\n",
    "        if (w < 100 and w > 50 and h > 30) and w > 1.3*h:\n",
    "\n",
    "            new_img = img[y:y+h, x:x+w]\n",
    "            #img2 = cv2.rectangle(img2,(x,y),(x+h,y+w),(255,255,255), 2)\n",
    "            new_images.append([new_dir+str(row) + '.png', new_img])\n",
    "    #         cv2.imwrite(new_dir+str(row) + '.png', new_img)\n",
    "            row +=1\n",
    "            retval.append(c)\n",
    "        \n",
    "    return new_images,retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeImage(contours):\n",
    "    row = 0\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        #img2 = cv2.rectangle(img2,(x,y),(x+h,y+w),(255,255,255), 2)\n",
    "        new_images.append([new_dir+str(row) + '.png', new_img])\n",
    "        cv2.imwrite(new_dir+str(row) + '.png', new_img)\n",
    "        row +=1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortSelectedContours(contours):\n",
    "    retval = []\n",
    "    contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
    "    for i in range(0,11):\n",
    "        top_7 = contours[7*i:7*i + 7]\n",
    "        top_7 = sorted(top_7, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        retval = retval + top_7\n",
    "    retval.append(contours[-1])\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    print(os.getcwd())\n",
    "    #os.chdir('../ivpminipro/mini project')\n",
    "#     img2 = cv2.imread('sample2.jpg')\n",
    "    img = cv2.imread('sample1.jpg',0)\n",
    "    global new_dir\n",
    "    new_dir = \"dir1/\"\n",
    "#     os.mkdir(new_dir) \n",
    "    \n",
    "    (thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "\n",
    "    #img_bin = applyAdaptive(img)\n",
    "    img_bin_final = main_function(img_bin)\n",
    "    \n",
    "    contours = getContours(img_bin_final)\n",
    "    #print(contours)\n",
    "    \n",
    "    new_images = []\n",
    "    selected_contours = []\n",
    "    new_images,selected_contours = getNewImages(contours)\n",
    "    \n",
    "    print(len(new_images))\n",
    "\n",
    "    if len(new_images) != 78:\n",
    "        print('Applying Adaptive filtering')\n",
    "        new_image = []\n",
    "        img_bin = applyAdaptive(img)\n",
    "        \n",
    "        img_bin_final = main_function(img_bin)\n",
    "    \n",
    "        contours = getContours(img_bin_final)\n",
    "        \n",
    "        new_images,selected_contours = getNewImages(contours)\n",
    "        \n",
    "        \n",
    "    selected_contours = sortSelectedContours(selected_contours)\n",
    "\n",
    "    storeImage(selected_contours)\n",
    "#         for image in new_images:\n",
    "#             cv2.imwrite(image[0],image[1])\n",
    "    \n",
    "    \n",
    "#         col = col - 1\n",
    "#         if col == -1 :\n",
    "#             row +=1\n",
    "#             col = 6\n",
    "# cv2.imshow('boxes.jpg',img2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contours[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between(p1, p2):\n",
    "    \"\"\"Returns the scalar distance between two points\"\"\"\n",
    "    a = p2[0] - p1[0]\n",
    "    b = p2[1] - p1[1]\n",
    "    return np.sqrt((a ** 2) + (b ** 2))\n",
    "\n",
    "def find_corners_of_largest_polygon(img):\n",
    "    \"\"\"Finds the 4 extreme corners of the largest contour in the image.\"\"\"\n",
    "    contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)  # Sort by area, descending\n",
    "    polygon = contours[0]  # Largest image\n",
    "\n",
    "    # Use of `operator.itemgetter` with `max` and `min` allows us to get the index of the point\n",
    "    # Each point is an array of 1 coordinate, hence the [0] getter, then [0] or [1] used to get x and y respectively.\n",
    "\n",
    "    # Bottom-right point has the largest (x + y) value\n",
    "    # Top-left has point smallest (x + y) value\n",
    "    # Bottom-left point has smallest (x - y) value\n",
    "    # Top-right point has largest (x - y) value\n",
    "    bottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    bottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "    top_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\n",
    "    # Return an array of all 4 points using the indices\n",
    "    # Each point is in its own array of one coordinate\n",
    "    return [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]\n",
    "\n",
    "def crop_and_warp(img, crop_rect):\n",
    "    \"\"\"Crops and warps a rectangular section from an image into a square of similar size.\"\"\"\n",
    "\n",
    "    # Rectangle described by top left, top right, bottom right and bottom left points\n",
    "    top_left, top_right, bottom_right, bottom_left = crop_rect[0], crop_rect[1], crop_rect[2], crop_rect[3]\n",
    "\n",
    "    # Explicitly set the data type to float32 or `getPerspectiveTransform` will throw an error\n",
    "    src = np.array([top_left, top_right, bottom_right, bottom_left], dtype='float32')\n",
    "\n",
    "    # Get the longest side in the rectangle\n",
    "    length = max([\n",
    "    distance_between(bottom_right, top_right),\n",
    "    distance_between(top_left, bottom_left),\n",
    "    ])\n",
    "    # width = min([\n",
    "    # distance_between(bottom_right-1, bottom_left-1),\n",
    "    # distance_between(top_left, top_right)\n",
    "    # ])\n",
    "    w1 = distance_between(top_left, top_right)\n",
    "    w2 = distance_between(bottom_right, bottom_left)\n",
    "    width =  distance_between(top_left, top_right)\n",
    "    print(\"Top \", w1,\" Bottom \",w2)\n",
    "    # Describe a square with side of the calculated length, this is the new perspective we want to warp to\n",
    "    dst = np.array([[0,0], [width - 1, 0], [width - 1, length - 1], [0, length - 1]], dtype='float32')\n",
    "\n",
    "    # Gets the transformation matrix for skewing the image to fit a square by comparing the 4 before and after points\n",
    "    m = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Performs the transformation on the original image\n",
    "    img = cv2.warpPerspective(img, m, (int(width), int(length)))\n",
    "    cv2.imwrite('a.jpg',img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(r,theta,q,alpha):\n",
    "    sint = np.sin(theta)\n",
    "    sina = np.sin(alpha)\n",
    "    cost = np.cos(theta)\n",
    "    cosa = np.cos(alpha)\n",
    "    y = (r*cosa - q*cost)//(sint*cosa - cost*sina)\n",
    "    x = (r*sina - q*sint)//(cost*sina - cosa*sint)\n",
    "    \n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_something (img,lines) :\n",
    "    retval = []\n",
    "    diff = []\n",
    "    count = 0\n",
    "    for i in range(len(lines)-1) :\n",
    "        diff.append(abs(lines[i][0] - lines[i+1][0]))\n",
    "        \n",
    "    print(diff)\n",
    "    for i in range(len(diff)-1):\n",
    "        if abs(diff[i] -diff[i+1]) <20:\n",
    "            retval.append(lines[i][0])\n",
    "            retval.append(lines[i+1][0])\n",
    "            count += 1\n",
    "        elif count < 13:\n",
    "            count =0\n",
    "            retval = []\n",
    "            \n",
    "    retval = list(dict.fromkeys(retval))\n",
    "    retval.sort()\n",
    "    \n",
    "    final_answer = [ value for value in lines if value[0] in retval] \n",
    "   \n",
    "    return final_answer\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, new_lines, thresh) :\n",
    "    count =0\n",
    "    prev = 0\n",
    "    retval = []\n",
    "    \n",
    "    for line in new_lines:\n",
    "        \n",
    "        r = line[0]\n",
    "        theta = line[1]\n",
    "        \n",
    "        \n",
    "        if abs(abs(prev) - abs(r)) < thresh and count != 0:\n",
    "            prev = r\n",
    "            continue\n",
    "#         if count in [0,14,15,16] and math.ceil(theta) == 2:\n",
    "#             prev = r\n",
    "#             count+=1\n",
    "#             continue           \n",
    "            \n",
    "        prev = r\n",
    "        a = np.cos(theta)\n",
    "        b= np.sin(theta)\n",
    "\n",
    "        x0 = a*r\n",
    "        y0 = b*r\n",
    "\n",
    "        x1 = int(x0 - 1000*b)\n",
    "        y1 = int(y0 + 1000*a)\n",
    "\n",
    "        x2 = int(x0 + 1000*b)\n",
    "        y2 = int(y0 - 1000*a)\n",
    "        count +=1\n",
    "        retval.append([r,theta])\n",
    "        cv2.line(img,(x1,y1), (x2,y2), (0,0,255),2)\n",
    "    print(count)\n",
    "    return img, retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "8\n",
      "[52.0, 49.0, 49.0, 50.0, 53.0, 49.0, 49.0, 49.0, 51.0, 54.0, 51.0, 54.0, 49.0, 55.0, 52.0]\n",
      "[[180.0, 1.6231562], [232.0, 1.6231562], [281.0, 1.6231562], [330.0, 1.6231562], [380.0, 1.6231562], [433.0, 1.6057029], [482.0, 1.6057029], [531.0, 1.6057029], [580.0, 1.6057029], [631.0, 1.6057029], [685.0, 1.5882496], [736.0, 1.5882496], [790.0, 1.5882496]]\n",
      "[[40.0, 0.034906585], [113.0, 0.034906585], [184.0, 0.034906585], [254.0, 0.034906585], [324.0, 0.034906585], [393.0, 0.034906585], [454.0, 0.017453292], [549.0, 0.017453292]]\n",
      "13\n",
      "8\n",
      "[[[33.0, 182.0], [106.0, 185.0], [177.0, 189.0], [247.0, 193.0], [317.0, 196.0], [386.0, 200.0], [450.0, 203.0], [545.0, 208.0]], [[31.0, 233.0], [104.0, 237.0], [175.0, 241.0], [245.0, 245.0], [315.0, 248.0], [384.0, 252.0], [449.0, 255.0], [544.0, 260.0]], [[30.0, 282.0], [103.0, 286.0], [173.0, 290.0], [243.0, 294.0], [313.0, 297.0], [382.0, 301.0], [448.0, 304.0], [543.0, 309.0]], [[28.0, 331.0], [101.0, 335.0], [172.0, 339.0], [242.0, 343.0], [312.0, 346.0], [381.0, 350.0], [447.0, 353.0], [542.0, 358.0]], [[26.0, 381.0], [99.0, 385.0], [170.0, 389.0], [240.0, 393.0], [310.0, 396.0], [379.0, 400.0], [447.0, 403.0], [541.0, 408.0]], [[24.0, 434.0], [97.0, 436.0], [168.0, 439.0], [238.0, 441.0], [308.0, 444.0], [377.0, 446.0], [446.0, 448.0], [541.0, 452.0]], [[23.0, 483.0], [96.0, 485.0], [167.0, 488.0], [237.0, 490.0], [306.0, 493.0], [375.0, 495.0], [445.0, 497.0], [540.0, 501.0]], [[21.0, 532.0], [94.0, 534.0], [165.0, 537.0], [235.0, 539.0], [305.0, 541.0], [374.0, 544.0], [444.0, 546.0], [539.0, 550.0]], [[19.0, 581.0], [92.0, 583.0], [163.0, 586.0], [233.0, 588.0], [303.0, 590.0], [372.0, 593.0], [443.0, 595.0], [538.0, 599.0]], [[17.0, 632.0], [90.0, 634.0], [161.0, 637.0], [231.0, 639.0], [301.0, 641.0], [370.0, 644.0], [442.0, 646.0], [537.0, 650.0]], [[16.0, 685.0], [89.0, 686.0], [160.0, 687.0], [230.0, 689.0], [300.0, 690.0], [369.0, 691.0], [441.0, 692.0], [536.0, 694.0]], [[14.0, 736.0], [87.0, 737.0], [158.0, 738.0], [228.0, 740.0], [298.0, 741.0], [367.0, 742.0], [441.0, 743.0], [536.0, 745.0]], [[12.0, 790.0], [85.0, 791.0], [156.0, 792.0], [226.0, 794.0], [296.0, 795.0], [365.0, 796.0], [440.0, 797.0], [535.0, 799.0]]]\n"
     ]
    }
   ],
   "source": [
    "# Python program to illustrate HoughLine \n",
    "# method for line detection \n",
    "import cv2 \n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "# Reading the required image in \n",
    "# which operations are to be done. \n",
    "# Make sure that the image is in the same \n",
    "# directory in which this python program is \n",
    "img = cv2.imread('sample3.jpg') \n",
    "img_crop = img.copy()\n",
    "# Convert the img to grayscale \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# Apply edge detection method on the image \n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3) \n",
    "\n",
    "# This returns an array of r and theta values \n",
    "lines = cv2.HoughLines(edges,1,np.pi/180, 200) \n",
    "\n",
    "# The below for loop runs till r and theta values \n",
    "# are in the range of the 2d array \n",
    "horizontal_lines = []\n",
    "vertical_lines = []\n",
    "points = []\n",
    "for line in lines:\n",
    "    for r,theta in line:\n",
    "        \n",
    "        if math.ceil(theta) == 2 :\n",
    "            horizontal_lines.append([r,theta])\n",
    "        else:\n",
    "            vertical_lines.append([r,theta])\n",
    "\n",
    "\n",
    "horizontal_lines.sort(key=lambda x: x[0])\n",
    "vertical_lines.sort(key=lambda x: abs(x[0]))\n",
    "# print(horizontal_lines)\n",
    "# print(vertical_lines)\n",
    "#print(lines)\n",
    "\n",
    "img_copy = img.copy()\n",
    "img,horizontal_lines = draw_lines(img, horizontal_lines,12 )\n",
    "img, vertical_lines = draw_lines(img, vertical_lines, 16)\n",
    "\n",
    "\n",
    "horizontal_lines = find_something(img,horizontal_lines)\n",
    "horizontal_lines = horizontal_lines[:13]\n",
    "print(horizontal_lines)\n",
    "print(vertical_lines)\n",
    "img_copy,horizontal_lines = draw_lines(img_copy, horizontal_lines,12 )\n",
    "img_copy, vertical_lines = draw_lines(img_copy, vertical_lines, 16)\n",
    "\n",
    "#x0,y0 = intersection(horizontal_lines[0],vertical_lines[0])\n",
    "# All the changes made in the input image are finally \n",
    "# written on a new image houghlines.jpg \n",
    "cv2.imwrite('linesDetected3.jpg', img_copy) \n",
    "\n",
    "for i in range(len(horizontal_lines)):\n",
    "    points_temp = []\n",
    "    for j in range(len(vertical_lines)):\n",
    "        points_temp.append(intersection(horizontal_lines[i][0],horizontal_lines[i][1],vertical_lines[j][0],vertical_lines[j][1]))\n",
    "    points.append(points_temp)\n",
    "print(points)\n",
    "\n",
    "new_images = []\n",
    "new_dir = \"dir3/\"\n",
    "row =0 \n",
    "for i in range(len(points)-1) :\n",
    "    for j in range(len(points[0])-1):\n",
    "        new_img = img_crop[int(points[i][j][1]) : int(points[i+1][j][1]), int(points[i][j][0]) : int(points[i][j+1][0])]\n",
    "        new_images.append([new_dir+str(row) + '.png', new_img])\n",
    "        cv2.imwrite(new_dir+str(row) + '.png', new_img)\n",
    "        row+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
